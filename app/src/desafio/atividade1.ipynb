{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34552bae",
   "metadata": {},
   "source": [
    "## Atividade 1\n",
    "\n",
    "### 1 - Crie uma consulta que mostre, nesta ordem, Nome, Estado e Status <br>\n",
    "### 2 - Crie uma consulta que mostre apenas os Clientes do Status \"Platinum\" e \"Gold\" <br>\n",
    "### 3 - Demostre quanto cada Status de Clientes representa em Vendas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee3bda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as Func\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Criar uma SparkSession\n",
    "spark = SparkSession.builder.appName(\"Exemplo de Dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61d5d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o schema de Clientes\n",
    "clientes_schema = StructType([\n",
    "    StructField(\"ClienteID\", LongType(), True),\n",
    "    StructField(\"Cliente\", StringType(), True),\n",
    "    StructField(\"Estado\", StringType(), True),\n",
    "    StructField(\"Genero\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Carregar o arquivo Parquet aplicando o schema previamente definido para a tabela de Clientes\n",
    "path_cliente = \"../../arquivos/download/Atividades/Clientes.parquet\"\n",
    "df_clientes = spark.read.format(\"parquet\").schema(clientes_schema).load(path_cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f346911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------+\n",
      "|                Nome|Estado|  Status|\n",
      "+--------------------+------+--------+\n",
      "|    Alberto Monsanto|    RN|    Gold|\n",
      "|       Anna Carvajal|    RS|    Gold|\n",
      "|       Bento Quintão|    SP|    Gold|\n",
      "|       Carminda Dias|    AM|    Gold|\n",
      "|       Cláudio Jorge|    TO|    Gold|\n",
      "|     Dionísio Saltão|    PR|    Gold|\n",
      "|    Firmino Meireles|    AM|    Gold|\n",
      "| Honorina Villaverde|    PE|    Gold|\n",
      "|   Iracema Rodríguez|    BA|    Gold|\n",
      "|    Adriana Guedelha|    RO|Platinum|\n",
      "|       Flor Vilanova|    CE|Platinum|\n",
      "|     Ibijara Botelho|    RR|Platinum|\n",
      "|          Joana Ataí|    GO|Platinum|\n",
      "|Adelina Buenaventura|    RJ|  Silver|\n",
      "|        Adelino Gago|    RJ|  Silver|\n",
      "|     Adolfo Patrício|    PE|  Silver|\n",
      "|       Adélio Lisboa|    SE|  Silver|\n",
      "|       Adérito Bahía|    MA|  Silver|\n",
      "|       Aida Dorneles|    RN|  Silver|\n",
      "|   Alarico Quinterno|    AC|  Silver|\n",
      "+--------------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consulta para buscar o clientes por ordem de Nome, Estado e Status.\n",
    "df_clientes.select(\n",
    "    Func.col(\"Cliente\").alias(\"Nome\"), \n",
    "    \"Estado\", \n",
    "    \"Status\"\n",
    "    ) \\\n",
    "    .orderBy(\n",
    "        Func.col(\"Status\").asc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac018c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|               Nome|  Status|\n",
      "+-------------------+--------+\n",
      "|   Alberto Monsanto|    Gold|\n",
      "|      Anna Carvajal|    Gold|\n",
      "|      Bento Quintão|    Gold|\n",
      "|      Carminda Dias|    Gold|\n",
      "|      Cláudio Jorge|    Gold|\n",
      "|    Dionísio Saltão|    Gold|\n",
      "|   Firmino Meireles|    Gold|\n",
      "|Honorina Villaverde|    Gold|\n",
      "|  Iracema Rodríguez|    Gold|\n",
      "|   Adriana Guedelha|Platinum|\n",
      "|      Flor Vilanova|Platinum|\n",
      "|    Ibijara Botelho|Platinum|\n",
      "|         Joana Ataí|Platinum|\n",
      "+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consulta para buscar o Nome do Cliente que tenha o Status \"Gold\" ou \"Platinum\"\n",
    "df_clientes.select(\n",
    "    Func.col(\"Cliente\").alias(\"Nome\"),  \n",
    "    \"Status\"\n",
    "    ) \\\n",
    "    .where(\n",
    "        (Func.col(\"Status\") == \"Gold\") | \n",
    "        (Func.col(\"Status\") == \"Platinum\")) \\\n",
    "    .orderBy(Func.col(\"Status\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47079045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o schema de Vendas\n",
    "vendas_schema = StructType([\n",
    "    StructField(\"VendasID\", LongType(), True),\n",
    "    StructField(\"VendedorID\", LongType(), True),\n",
    "    StructField(\"ClienteID\", LongType(), True),\n",
    "    StructField(\"Data\", DateType(), True),\n",
    "    StructField(\"Total\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Carregar o arquivo Parquet aplicando o schema previamente definido para a tabela de Vendas\n",
    "path_vendas = \"../../arquivos/download/Atividades/Vendas.parquet\"\n",
    "df_vendas = spark.read.format(\"parquet\").load(path_vendas, schema = vendas_schema)\n",
    "\n",
    "# Convertendo a coluna \"Total\" para o tipo DecimalType com precisão de 10 dígitos e 2 casas decimais\n",
    "df_cast_vendas = df_vendas.withColumn(\"Total\", col(\"Total\").cast(DecimalType(10, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff641dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------------+\n",
      "|  Status|TotalVendas|QuantidadeVendas|\n",
      "+--------+-----------+----------------+\n",
      "|Platinum|   12584.68|               2|\n",
      "|  Silver| 3014291.36|             395|\n",
      "|    Gold|   27286.69|               3|\n",
      "+--------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Realizar o join entre df_clientes e df_vendas usando ClienteID como chave\n",
    "vendas_por_status = df_cast_vendas.join(\n",
    "    df_clientes,\n",
    "    df_cast_vendas[\"ClienteID\"] == df_clientes[\"ClienteID\"],  \n",
    "    \"inner\"\n",
    ").select(\n",
    "    df_clientes[\"Status\"],\n",
    "    df_cast_vendas[\"Total\"]\n",
    ")\n",
    "\n",
    "# Agrupar por Status e calcular o total de vendas para cada Status\n",
    "resultado = vendas_por_status.groupBy(\"Status\").agg(\n",
    "    Func.sum(\"Total\").alias(\"TotalVendas\"),  \n",
    "    Func.count(\"*\").alias(\"QuantidadeVendas\")  \n",
    ")\n",
    "\n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7448261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o Spark no final do script, se ainda não foi parado\n",
    "if spark.sparkContext._jsc.sc().isStopped() == False:\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
